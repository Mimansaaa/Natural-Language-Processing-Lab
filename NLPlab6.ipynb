{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPNePWvil80VOPKK4XmaVhI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"en-lZBwzGzuj","executionInfo":{"status":"ok","timestamp":1712570138289,"user_tz":-330,"elapsed":11118,"user":{"displayName":"Mimansa","userId":"06843747441768994787"}},"outputId":"c3bc48bd-cc41-4f3f-a44a-71c524b7d007"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n","/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n","  warn(RuntimeWarning(msg))\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n","  warn(RuntimeWarning(msg))\n","[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"]}],"source":["!pip install nltk\n","!python -m nltk.downloader stopwords\n","!python -m nltk.downloader vader_lexicon\n"]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","\n","def extract_text_from_website(url):\n","    response = requests.get(url)\n","    if response.status_code == 200:\n","        # Parse the HTML content using BeautifulSoup\n","        soup = BeautifulSoup(response.content, 'html.parser')\n","\n","        text_elements = soup.find_all(text=True)\n","        # Filtering the text elements\n","        filtered_text = [element.strip() for element in text_elements if\n","                         element.strip() and element.parent.name not in ['script', 'style']]\n","\n","        extracted_text = '\\n'.join(filtered_text)\n","        return extracted_text\n","    else:\n","        print(\"Failed to fetch website content.\")\n","        return None\n","\n","def display_extracted_text(text, num_lines=10):\n","    print(\"!!!! Top {} Lines of Extracted Text from Website !!!!\\n\".format(num_lines))\n","    lines = text.split('\\n')[:num_lines]\n","    for line in lines:\n","        print(line)\n","\n","def main():\n","    url = input(\"Enter the URL of the website: \")\n","    extracted_text = extract_text_from_website(url)\n","    if extracted_text:\n","        display_extracted_text(extracted_text, num_lines=10)\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mtfk9XeKIb0L","executionInfo":{"status":"ok","timestamp":1713775270731,"user_tz":-330,"elapsed":5480,"user":{"displayName":"Mimansa","userId":"06843747441768994787"}},"outputId":"9508ffd4-0650-4945-996a-de132adafadc"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter the URL of the website: https://en.wikipedia.org/wiki/Portal:Current_events\n","!!!! Top 10 Lines of Extracted Text from Website !!!!\n","\n","html\n","Portal:Current events - Wikipedia\n","Jump to content\n","Main menu\n","Main menu\n","move to sidebar\n","hide\n","Navigation\n","Main page\n","Contents\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-2-cac9f090ae30>:10: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n","  text_elements = soup.find_all(text=True)\n"]}]}]}